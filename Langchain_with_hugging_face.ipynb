{
  "metadata": {
    "kernelspec": {
      "language": "python",
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.11.13",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "kaggle": {
      "accelerator": "nvidiaTeslaT4",
      "dataSources": [],
      "dockerImageVersionId": 31090,
      "isInternetEnabled": true,
      "language": "python",
      "sourceType": "notebook",
      "isGpuEnabled": true
    },
    "colab": {
      "name": "Langchain with hugging face",
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat_minor": 0,
  "nbformat": 4,
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Nancy240/LangChain-with-HuggingFace-Question-Answering-System/blob/main/Langchain_with_hugging_face.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "## Libraries Required\n",
        "!pip install langchain-huggingface\n",
        "## For API Calls\n",
        "!pip install huggingface_hub\n",
        "!pip install transformers\n",
        "!pip install accelerate\n",
        "!pip install  bitsandbytes\n",
        "!pip install langchain"
      ],
      "metadata": {
        "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
        "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-07-18T12:49:12.52594Z",
          "iopub.execute_input": "2025-07-18T12:49:12.526196Z",
          "iopub.status.idle": "2025-07-18T12:51:00.593602Z",
          "shell.execute_reply.started": "2025-07-18T12:49:12.52617Z",
          "shell.execute_reply": "2025-07-18T12:51:00.592502Z"
        },
        "id": "K8ma_ewU3nAH",
        "outputId": "1869e0d0-3f76-4eb7-d9ea-a87cae9739db"
      },
      "outputs": [
        {
          "name": "stdout",
          "text": "Collecting langchain-huggingface\n  Downloading langchain_huggingface-0.3.0-py3-none-any.whl.metadata (996 bytes)\nRequirement already satisfied: langchain-core<1.0.0,>=0.3.65 in /usr/local/lib/python3.11/dist-packages (from langchain-huggingface) (0.3.66)\nRequirement already satisfied: tokenizers>=0.19.1 in /usr/local/lib/python3.11/dist-packages (from langchain-huggingface) (0.21.2)\nRequirement already satisfied: huggingface-hub>=0.30.2 in /usr/local/lib/python3.11/dist-packages (from langchain-huggingface) (0.33.1)\nRequirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.30.2->langchain-huggingface) (3.18.0)\nRequirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.30.2->langchain-huggingface) (2025.5.1)\nRequirement already satisfied: packaging>=20.9 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.30.2->langchain-huggingface) (25.0)\nRequirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.30.2->langchain-huggingface) (6.0.2)\nRequirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.30.2->langchain-huggingface) (2.32.4)\nRequirement already satisfied: tqdm>=4.42.1 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.30.2->langchain-huggingface) (4.67.1)\nRequirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.30.2->langchain-huggingface) (4.14.0)\nRequirement already satisfied: hf-xet<2.0.0,>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.30.2->langchain-huggingface) (1.1.5)\nRequirement already satisfied: langsmith>=0.3.45 in /usr/local/lib/python3.11/dist-packages (from langchain-core<1.0.0,>=0.3.65->langchain-huggingface) (0.4.1)\nRequirement already satisfied: tenacity!=8.4.0,<10.0.0,>=8.1.0 in /usr/local/lib/python3.11/dist-packages (from langchain-core<1.0.0,>=0.3.65->langchain-huggingface) (8.5.0)\nRequirement already satisfied: jsonpatch<2.0,>=1.33 in /usr/local/lib/python3.11/dist-packages (from langchain-core<1.0.0,>=0.3.65->langchain-huggingface) (1.33)\nCollecting packaging>=20.9 (from huggingface-hub>=0.30.2->langchain-huggingface)\n  Downloading packaging-24.2-py3-none-any.whl.metadata (3.2 kB)\nRequirement already satisfied: pydantic>=2.7.4 in /usr/local/lib/python3.11/dist-packages (from langchain-core<1.0.0,>=0.3.65->langchain-huggingface) (2.11.7)\nRequirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.11/dist-packages (from jsonpatch<2.0,>=1.33->langchain-core<1.0.0,>=0.3.65->langchain-huggingface) (3.0.0)\nRequirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from langsmith>=0.3.45->langchain-core<1.0.0,>=0.3.65->langchain-huggingface) (0.28.1)\nRequirement already satisfied: orjson<4.0.0,>=3.9.14 in /usr/local/lib/python3.11/dist-packages (from langsmith>=0.3.45->langchain-core<1.0.0,>=0.3.65->langchain-huggingface) (3.10.18)\nRequirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from langsmith>=0.3.45->langchain-core<1.0.0,>=0.3.65->langchain-huggingface) (1.0.0)\nRequirement already satisfied: zstandard<0.24.0,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from langsmith>=0.3.45->langchain-core<1.0.0,>=0.3.65->langchain-huggingface) (0.23.0)\nRequirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic>=2.7.4->langchain-core<1.0.0,>=0.3.65->langchain-huggingface) (0.7.0)\nRequirement already satisfied: pydantic-core==2.33.2 in /usr/local/lib/python3.11/dist-packages (from pydantic>=2.7.4->langchain-core<1.0.0,>=0.3.65->langchain-huggingface) (2.33.2)\nRequirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from pydantic>=2.7.4->langchain-core<1.0.0,>=0.3.65->langchain-huggingface) (0.4.1)\nRequirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface-hub>=0.30.2->langchain-huggingface) (3.4.2)\nRequirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface-hub>=0.30.2->langchain-huggingface) (3.10)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface-hub>=0.30.2->langchain-huggingface) (2.5.0)\nRequirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface-hub>=0.30.2->langchain-huggingface) (2025.6.15)\nRequirement already satisfied: anyio in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.23.0->langsmith>=0.3.45->langchain-core<1.0.0,>=0.3.65->langchain-huggingface) (4.9.0)\nRequirement already satisfied: httpcore==1.* in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.23.0->langsmith>=0.3.45->langchain-core<1.0.0,>=0.3.65->langchain-huggingface) (1.0.9)\nRequirement already satisfied: h11>=0.16 in /usr/local/lib/python3.11/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->langsmith>=0.3.45->langchain-core<1.0.0,>=0.3.65->langchain-huggingface) (0.16.0)\nRequirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.11/dist-packages (from anyio->httpx<1,>=0.23.0->langsmith>=0.3.45->langchain-core<1.0.0,>=0.3.65->langchain-huggingface) (1.3.1)\nDownloading langchain_huggingface-0.3.0-py3-none-any.whl (27 kB)\nDownloading packaging-24.2-py3-none-any.whl (65 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m65.5/65.5 kB\u001b[0m \u001b[31m1.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hInstalling collected packages: packaging, langchain-huggingface\n  Attempting uninstall: packaging\n    Found existing installation: packaging 25.0\n    Uninstalling packaging-25.0:\n      Successfully uninstalled packaging-25.0\n\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\nbigframes 2.8.0 requires google-cloud-bigquery-storage<3.0.0,>=2.30.0, which is not installed.\ndatasets 3.6.0 requires fsspec[http]<=2025.3.0,>=2023.1.0, but you have fsspec 2025.5.1 which is incompatible.\ncesium 0.12.4 requires numpy<3.0,>=2.0, but you have numpy 1.26.4 which is incompatible.\npandas-gbq 0.29.1 requires google-api-core<3.0.0,>=2.10.2, but you have google-api-core 1.34.1 which is incompatible.\nthinc 8.3.6 requires numpy<3.0.0,>=2.0.0, but you have numpy 1.26.4 which is incompatible.\nplotnine 0.14.5 requires matplotlib>=3.8.0, but you have matplotlib 3.7.2 which is incompatible.\ndataproc-spark-connect 0.7.5 requires google-api-core>=2.19, but you have google-api-core 1.34.1 which is incompatible.\nbigframes 2.8.0 requires google-cloud-bigquery[bqstorage,pandas]>=3.31.0, but you have google-cloud-bigquery 3.25.0 which is incompatible.\nbigframes 2.8.0 requires rich<14,>=12.4.4, but you have rich 14.0.0 which is incompatible.\nmlxtend 0.23.4 requires scikit-learn>=1.3.1, but you have scikit-learn 1.2.2 which is incompatible.\u001b[0m\u001b[31m\n\u001b[0mSuccessfully installed langchain-huggingface-0.3.0 packaging-24.2\nRequirement already satisfied: huggingface_hub in /usr/local/lib/python3.11/dist-packages (0.33.1)\nRequirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from huggingface_hub) (3.18.0)\nRequirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.11/dist-packages (from huggingface_hub) (2025.5.1)\nRequirement already satisfied: packaging>=20.9 in /usr/local/lib/python3.11/dist-packages (from huggingface_hub) (24.2)\nRequirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from huggingface_hub) (6.0.2)\nRequirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from huggingface_hub) (2.32.4)\nRequirement already satisfied: tqdm>=4.42.1 in /usr/local/lib/python3.11/dist-packages (from huggingface_hub) (4.67.1)\nRequirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.11/dist-packages (from huggingface_hub) (4.14.0)\nRequirement already satisfied: hf-xet<2.0.0,>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from huggingface_hub) (1.1.5)\nRequirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface_hub) (3.4.2)\nRequirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface_hub) (3.10)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface_hub) (2.5.0)\nRequirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface_hub) (2025.6.15)\nRequirement already satisfied: transformers in /usr/local/lib/python3.11/dist-packages (4.52.4)\nRequirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from transformers) (3.18.0)\nRequirement already satisfied: huggingface-hub<1.0,>=0.30.0 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.33.1)\nRequirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.11/dist-packages (from transformers) (1.26.4)\nRequirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from transformers) (24.2)\nRequirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from transformers) (6.0.2)\nRequirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.11/dist-packages (from transformers) (2024.11.6)\nRequirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from transformers) (2.32.4)\nRequirement already satisfied: tokenizers<0.22,>=0.21 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.21.2)\nRequirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.5.3)\nRequirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.11/dist-packages (from transformers) (4.67.1)\nRequirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.30.0->transformers) (2025.5.1)\nRequirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.30.0->transformers) (4.14.0)\nRequirement already satisfied: hf-xet<2.0.0,>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.30.0->transformers) (1.1.5)\nRequirement already satisfied: mkl_fft in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->transformers) (1.3.8)\nRequirement already satisfied: mkl_random in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->transformers) (1.2.4)\nRequirement already satisfied: mkl_umath in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->transformers) (0.1.1)\nRequirement already satisfied: mkl in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->transformers) (2025.2.0)\nRequirement already satisfied: tbb4py in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->transformers) (2022.2.0)\nRequirement already satisfied: mkl-service in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->transformers) (2.4.1)\nRequirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (3.4.2)\nRequirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (3.10)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (2.5.0)\nRequirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (2025.6.15)\nRequirement already satisfied: intel-openmp<2026,>=2024 in /usr/local/lib/python3.11/dist-packages (from mkl->numpy>=1.17->transformers) (2024.2.0)\nRequirement already satisfied: tbb==2022.* in /usr/local/lib/python3.11/dist-packages (from mkl->numpy>=1.17->transformers) (2022.2.0)\nRequirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.11/dist-packages (from tbb==2022.*->mkl->numpy>=1.17->transformers) (1.4.0)\nRequirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.11/dist-packages (from mkl_umath->numpy>=1.17->transformers) (2024.2.0)\nRequirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.11/dist-packages (from intel-openmp<2026,>=2024->mkl->numpy>=1.17->transformers) (2024.2.0)\nRequirement already satisfied: accelerate in /usr/local/lib/python3.11/dist-packages (1.8.1)\nRequirement already satisfied: numpy<3.0.0,>=1.17 in /usr/local/lib/python3.11/dist-packages (from accelerate) (1.26.4)\nRequirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from accelerate) (24.2)\nRequirement already satisfied: psutil in /usr/local/lib/python3.11/dist-packages (from accelerate) (7.0.0)\nRequirement already satisfied: pyyaml in /usr/local/lib/python3.11/dist-packages (from accelerate) (6.0.2)\nRequirement already satisfied: torch>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from accelerate) (2.6.0+cu124)\nRequirement already satisfied: huggingface_hub>=0.21.0 in /usr/local/lib/python3.11/dist-packages (from accelerate) (0.33.1)\nRequirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.11/dist-packages (from accelerate) (0.5.3)\nRequirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from huggingface_hub>=0.21.0->accelerate) (3.18.0)\nRequirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.11/dist-packages (from huggingface_hub>=0.21.0->accelerate) (2025.5.1)\nRequirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from huggingface_hub>=0.21.0->accelerate) (2.32.4)\nRequirement already satisfied: tqdm>=4.42.1 in /usr/local/lib/python3.11/dist-packages (from huggingface_hub>=0.21.0->accelerate) (4.67.1)\nRequirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.11/dist-packages (from huggingface_hub>=0.21.0->accelerate) (4.14.0)\nRequirement already satisfied: hf-xet<2.0.0,>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from huggingface_hub>=0.21.0->accelerate) (1.1.5)\nRequirement already satisfied: mkl_fft in /usr/local/lib/python3.11/dist-packages (from numpy<3.0.0,>=1.17->accelerate) (1.3.8)\nRequirement already satisfied: mkl_random in /usr/local/lib/python3.11/dist-packages (from numpy<3.0.0,>=1.17->accelerate) (1.2.4)\nRequirement already satisfied: mkl_umath in /usr/local/lib/python3.11/dist-packages (from numpy<3.0.0,>=1.17->accelerate) (0.1.1)\nRequirement already satisfied: mkl in /usr/local/lib/python3.11/dist-packages (from numpy<3.0.0,>=1.17->accelerate) (2025.2.0)\nRequirement already satisfied: tbb4py in /usr/local/lib/python3.11/dist-packages (from numpy<3.0.0,>=1.17->accelerate) (2022.2.0)\nRequirement already satisfied: mkl-service in /usr/local/lib/python3.11/dist-packages (from numpy<3.0.0,>=1.17->accelerate) (2.4.1)\nRequirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate) (3.5)\nRequirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate) (3.1.6)\nCollecting nvidia-cuda-nvrtc-cu12==12.4.127 (from torch>=2.0.0->accelerate)\n  Downloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\nCollecting nvidia-cuda-runtime-cu12==12.4.127 (from torch>=2.0.0->accelerate)\n  Downloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\nCollecting nvidia-cuda-cupti-cu12==12.4.127 (from torch>=2.0.0->accelerate)\n  Downloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\nCollecting nvidia-cudnn-cu12==9.1.0.70 (from torch>=2.0.0->accelerate)\n  Downloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\nCollecting nvidia-cublas-cu12==12.4.5.8 (from torch>=2.0.0->accelerate)\n  Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\nCollecting nvidia-cufft-cu12==11.2.1.3 (from torch>=2.0.0->accelerate)\n  Downloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\nCollecting nvidia-curand-cu12==10.3.5.147 (from torch>=2.0.0->accelerate)\n  Downloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\nCollecting nvidia-cusolver-cu12==11.6.1.9 (from torch>=2.0.0->accelerate)\n  Downloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\nCollecting nvidia-cusparse-cu12==12.3.1.170 (from torch>=2.0.0->accelerate)\n  Downloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\nRequirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate) (0.6.2)\nRequirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate) (2.21.5)\nRequirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate) (12.4.127)\nCollecting nvidia-nvjitlink-cu12==12.4.127 (from torch>=2.0.0->accelerate)\n  Downloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\nRequirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate) (3.2.0)\nRequirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate) (1.13.1)\nRequirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch>=2.0.0->accelerate) (1.3.0)\nRequirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch>=2.0.0->accelerate) (3.0.2)\nRequirement already satisfied: intel-openmp<2026,>=2024 in /usr/local/lib/python3.11/dist-packages (from mkl->numpy<3.0.0,>=1.17->accelerate) (2024.2.0)\nRequirement already satisfied: tbb==2022.* in /usr/local/lib/python3.11/dist-packages (from mkl->numpy<3.0.0,>=1.17->accelerate) (2022.2.0)\nRequirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.11/dist-packages (from tbb==2022.*->mkl->numpy<3.0.0,>=1.17->accelerate) (1.4.0)\nRequirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.11/dist-packages (from mkl_umath->numpy<3.0.0,>=1.17->accelerate) (2024.2.0)\nRequirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface_hub>=0.21.0->accelerate) (3.4.2)\nRequirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface_hub>=0.21.0->accelerate) (3.10)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface_hub>=0.21.0->accelerate) (2.5.0)\nRequirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface_hub>=0.21.0->accelerate) (2025.6.15)\nRequirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.11/dist-packages (from intel-openmp<2026,>=2024->mkl->numpy<3.0.0,>=1.17->accelerate) (2024.2.0)\nDownloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl (363.4 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m4.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (13.8 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m104.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m0:01\u001b[0m\n\u001b[?25hDownloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (24.6 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.6/24.6 MB\u001b[0m \u001b[31m77.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (883 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m883.7/883.7 kB\u001b[0m \u001b[31m42.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl (664.8 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m2.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl (211.5 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m5.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl (56.3 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m31.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl (127.9 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m13.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl (207.5 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m2.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (21.1 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m82.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hInstalling collected packages: nvidia-nvjitlink-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, nvidia-cusparse-cu12, nvidia-cudnn-cu12, nvidia-cusolver-cu12\n  Attempting uninstall: nvidia-nvjitlink-cu12\n    Found existing installation: nvidia-nvjitlink-cu12 12.5.82\n    Uninstalling nvidia-nvjitlink-cu12-12.5.82:\n      Successfully uninstalled nvidia-nvjitlink-cu12-12.5.82\n  Attempting uninstall: nvidia-curand-cu12\n    Found existing installation: nvidia-curand-cu12 10.3.6.82\n    Uninstalling nvidia-curand-cu12-10.3.6.82:\n      Successfully uninstalled nvidia-curand-cu12-10.3.6.82\n  Attempting uninstall: nvidia-cufft-cu12\n    Found existing installation: nvidia-cufft-cu12 11.2.3.61\n    Uninstalling nvidia-cufft-cu12-11.2.3.61:\n      Successfully uninstalled nvidia-cufft-cu12-11.2.3.61\n  Attempting uninstall: nvidia-cuda-runtime-cu12\n    Found existing installation: nvidia-cuda-runtime-cu12 12.5.82\n    Uninstalling nvidia-cuda-runtime-cu12-12.5.82:\n      Successfully uninstalled nvidia-cuda-runtime-cu12-12.5.82\n  Attempting uninstall: nvidia-cuda-nvrtc-cu12\n    Found existing installation: nvidia-cuda-nvrtc-cu12 12.5.82\n    Uninstalling nvidia-cuda-nvrtc-cu12-12.5.82:\n      Successfully uninstalled nvidia-cuda-nvrtc-cu12-12.5.82\n  Attempting uninstall: nvidia-cuda-cupti-cu12\n    Found existing installation: nvidia-cuda-cupti-cu12 12.5.82\n    Uninstalling nvidia-cuda-cupti-cu12-12.5.82:\n      Successfully uninstalled nvidia-cuda-cupti-cu12-12.5.82\n  Attempting uninstall: nvidia-cublas-cu12\n    Found existing installation: nvidia-cublas-cu12 12.5.3.2\n    Uninstalling nvidia-cublas-cu12-12.5.3.2:\n      Successfully uninstalled nvidia-cublas-cu12-12.5.3.2\n  Attempting uninstall: nvidia-cusparse-cu12\n    Found existing installation: nvidia-cusparse-cu12 12.5.1.3\n    Uninstalling nvidia-cusparse-cu12-12.5.1.3:\n      Successfully uninstalled nvidia-cusparse-cu12-12.5.1.3\n  Attempting uninstall: nvidia-cudnn-cu12\n    Found existing installation: nvidia-cudnn-cu12 9.3.0.75\n    Uninstalling nvidia-cudnn-cu12-9.3.0.75:\n      Successfully uninstalled nvidia-cudnn-cu12-9.3.0.75\n  Attempting uninstall: nvidia-cusolver-cu12\n    Found existing installation: nvidia-cusolver-cu12 11.6.3.83\n    Uninstalling nvidia-cusolver-cu12-11.6.3.83:\n      Successfully uninstalled nvidia-cusolver-cu12-11.6.3.83\nSuccessfully installed nvidia-cublas-cu12-12.4.5.8 nvidia-cuda-cupti-cu12-12.4.127 nvidia-cuda-nvrtc-cu12-12.4.127 nvidia-cuda-runtime-cu12-12.4.127 nvidia-cudnn-cu12-9.1.0.70 nvidia-cufft-cu12-11.2.1.3 nvidia-curand-cu12-10.3.5.147 nvidia-cusolver-cu12-11.6.1.9 nvidia-cusparse-cu12-12.3.1.170 nvidia-nvjitlink-cu12-12.4.127\nCollecting bitsandbytes\n  Downloading bitsandbytes-0.46.1-py3-none-manylinux_2_24_x86_64.whl.metadata (10 kB)\nRequirement already satisfied: torch<3,>=2.2 in /usr/local/lib/python3.11/dist-packages (from bitsandbytes) (2.6.0+cu124)\nRequirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.11/dist-packages (from bitsandbytes) (1.26.4)\nRequirement already satisfied: mkl_fft in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->bitsandbytes) (1.3.8)\nRequirement already satisfied: mkl_random in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->bitsandbytes) (1.2.4)\nRequirement already satisfied: mkl_umath in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->bitsandbytes) (0.1.1)\nRequirement already satisfied: mkl in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->bitsandbytes) (2025.2.0)\nRequirement already satisfied: tbb4py in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->bitsandbytes) (2022.2.0)\nRequirement already satisfied: mkl-service in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->bitsandbytes) (2.4.1)\nRequirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch<3,>=2.2->bitsandbytes) (3.18.0)\nRequirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.11/dist-packages (from torch<3,>=2.2->bitsandbytes) (4.14.0)\nRequirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch<3,>=2.2->bitsandbytes) (3.5)\nRequirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch<3,>=2.2->bitsandbytes) (3.1.6)\nRequirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch<3,>=2.2->bitsandbytes) (2025.5.1)\nRequirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch<3,>=2.2->bitsandbytes) (12.4.127)\nRequirement already satisfied: nvidia-cuda-runtime-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch<3,>=2.2->bitsandbytes) (12.4.127)\nRequirement already satisfied: nvidia-cuda-cupti-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch<3,>=2.2->bitsandbytes) (12.4.127)\nRequirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /usr/local/lib/python3.11/dist-packages (from torch<3,>=2.2->bitsandbytes) (9.1.0.70)\nRequirement already satisfied: nvidia-cublas-cu12==12.4.5.8 in /usr/local/lib/python3.11/dist-packages (from torch<3,>=2.2->bitsandbytes) (12.4.5.8)\nRequirement already satisfied: nvidia-cufft-cu12==11.2.1.3 in /usr/local/lib/python3.11/dist-packages (from torch<3,>=2.2->bitsandbytes) (11.2.1.3)\nRequirement already satisfied: nvidia-curand-cu12==10.3.5.147 in /usr/local/lib/python3.11/dist-packages (from torch<3,>=2.2->bitsandbytes) (10.3.5.147)\nRequirement already satisfied: nvidia-cusolver-cu12==11.6.1.9 in /usr/local/lib/python3.11/dist-packages (from torch<3,>=2.2->bitsandbytes) (11.6.1.9)\nRequirement already satisfied: nvidia-cusparse-cu12==12.3.1.170 in /usr/local/lib/python3.11/dist-packages (from torch<3,>=2.2->bitsandbytes) (12.3.1.170)\nRequirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch<3,>=2.2->bitsandbytes) (0.6.2)\nRequirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch<3,>=2.2->bitsandbytes) (2.21.5)\nRequirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch<3,>=2.2->bitsandbytes) (12.4.127)\nRequirement already satisfied: nvidia-nvjitlink-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch<3,>=2.2->bitsandbytes) (12.4.127)\nRequirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch<3,>=2.2->bitsandbytes) (3.2.0)\nRequirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch<3,>=2.2->bitsandbytes) (1.13.1)\nRequirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch<3,>=2.2->bitsandbytes) (1.3.0)\nRequirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch<3,>=2.2->bitsandbytes) (3.0.2)\nRequirement already satisfied: intel-openmp<2026,>=2024 in /usr/local/lib/python3.11/dist-packages (from mkl->numpy>=1.17->bitsandbytes) (2024.2.0)\nRequirement already satisfied: tbb==2022.* in /usr/local/lib/python3.11/dist-packages (from mkl->numpy>=1.17->bitsandbytes) (2022.2.0)\nRequirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.11/dist-packages (from tbb==2022.*->mkl->numpy>=1.17->bitsandbytes) (1.4.0)\nRequirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.11/dist-packages (from mkl_umath->numpy>=1.17->bitsandbytes) (2024.2.0)\nRequirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.11/dist-packages (from intel-openmp<2026,>=2024->mkl->numpy>=1.17->bitsandbytes) (2024.2.0)\nDownloading bitsandbytes-0.46.1-py3-none-manylinux_2_24_x86_64.whl (72.9 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m72.9/72.9 MB\u001b[0m \u001b[31m24.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hInstalling collected packages: bitsandbytes\nSuccessfully installed bitsandbytes-0.46.1\nRequirement already satisfied: langchain in /usr/local/lib/python3.11/dist-packages (0.3.26)\nRequirement already satisfied: langchain-core<1.0.0,>=0.3.66 in /usr/local/lib/python3.11/dist-packages (from langchain) (0.3.66)\nRequirement already satisfied: langchain-text-splitters<1.0.0,>=0.3.8 in /usr/local/lib/python3.11/dist-packages (from langchain) (0.3.8)\nRequirement already satisfied: langsmith>=0.1.17 in /usr/local/lib/python3.11/dist-packages (from langchain) (0.4.1)\nRequirement already satisfied: pydantic<3.0.0,>=2.7.4 in /usr/local/lib/python3.11/dist-packages (from langchain) (2.11.7)\nRequirement already satisfied: SQLAlchemy<3,>=1.4 in /usr/local/lib/python3.11/dist-packages (from langchain) (2.0.41)\nRequirement already satisfied: requests<3,>=2 in /usr/local/lib/python3.11/dist-packages (from langchain) (2.32.4)\nRequirement already satisfied: PyYAML>=5.3 in /usr/local/lib/python3.11/dist-packages (from langchain) (6.0.2)\nRequirement already satisfied: tenacity!=8.4.0,<10.0.0,>=8.1.0 in /usr/local/lib/python3.11/dist-packages (from langchain-core<1.0.0,>=0.3.66->langchain) (8.5.0)\nRequirement already satisfied: jsonpatch<2.0,>=1.33 in /usr/local/lib/python3.11/dist-packages (from langchain-core<1.0.0,>=0.3.66->langchain) (1.33)\nRequirement already satisfied: packaging<25,>=23.2 in /usr/local/lib/python3.11/dist-packages (from langchain-core<1.0.0,>=0.3.66->langchain) (24.2)\nRequirement already satisfied: typing-extensions>=4.7 in /usr/local/lib/python3.11/dist-packages (from langchain-core<1.0.0,>=0.3.66->langchain) (4.14.0)\nRequirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from langsmith>=0.1.17->langchain) (0.28.1)\nRequirement already satisfied: orjson<4.0.0,>=3.9.14 in /usr/local/lib/python3.11/dist-packages (from langsmith>=0.1.17->langchain) (3.10.18)\nRequirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from langsmith>=0.1.17->langchain) (1.0.0)\nRequirement already satisfied: zstandard<0.24.0,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from langsmith>=0.1.17->langchain) (0.23.0)\nRequirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain) (0.7.0)\nRequirement already satisfied: pydantic-core==2.33.2 in /usr/local/lib/python3.11/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain) (2.33.2)\nRequirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain) (0.4.1)\nRequirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2->langchain) (3.4.2)\nRequirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2->langchain) (3.10)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2->langchain) (2.5.0)\nRequirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2->langchain) (2025.6.15)\nRequirement already satisfied: greenlet>=1 in /usr/local/lib/python3.11/dist-packages (from SQLAlchemy<3,>=1.4->langchain) (3.2.3)\nRequirement already satisfied: anyio in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.23.0->langsmith>=0.1.17->langchain) (4.9.0)\nRequirement already satisfied: httpcore==1.* in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.23.0->langsmith>=0.1.17->langchain) (1.0.9)\nRequirement already satisfied: h11>=0.16 in /usr/local/lib/python3.11/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->langsmith>=0.1.17->langchain) (0.16.0)\nRequirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.11/dist-packages (from jsonpatch<2.0,>=1.33->langchain-core<1.0.0,>=0.3.66->langchain) (3.0.0)\nRequirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.11/dist-packages (from anyio->httpx<1,>=0.23.0->langsmith>=0.1.17->langchain) (1.3.1)\n",
          "output_type": "stream"
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "from kaggle_secrets import UserSecretsClient\n",
        "\n",
        "# Access the user secrets\n",
        "user_secrets = UserSecretsClient()\n",
        "\n",
        "# Get your Hugging Face token (you must have added \"HUGGINGFACEHUB_API_TOKEN\" as a secret in Kaggle)\n",
        "sec_key = user_secrets.get_secret(\"HF_TOKEN\")\n",
        "\n",
        "# Optionally log in to Hugging Face\n",
        "from huggingface_hub import login\n",
        "login(token=sec_key)"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-07-18T12:51:00.596045Z",
          "iopub.execute_input": "2025-07-18T12:51:00.596352Z",
          "iopub.status.idle": "2025-07-18T12:51:01.379698Z",
          "shell.execute_reply.started": "2025-07-18T12:51:00.596324Z",
          "shell.execute_reply": "2025-07-18T12:51:01.379124Z"
        },
        "id": "SF1vagC33nAI"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "os.environ[\"HF_TOKEN\"]=sec_key"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-07-18T12:51:01.38029Z",
          "iopub.execute_input": "2025-07-18T12:51:01.380471Z",
          "iopub.status.idle": "2025-07-18T12:51:01.384425Z",
          "shell.execute_reply.started": "2025-07-18T12:51:01.380455Z",
          "shell.execute_reply": "2025-07-18T12:51:01.383513Z"
        },
        "id": "oo7e1Xo63nAJ"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_huggingface import HuggingFaceEndpoint"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-07-18T12:51:01.385287Z",
          "iopub.execute_input": "2025-07-18T12:51:01.38579Z",
          "iopub.status.idle": "2025-07-18T12:51:02.948208Z",
          "shell.execute_reply.started": "2025-07-18T12:51:01.385766Z",
          "shell.execute_reply": "2025-07-18T12:51:02.947452Z"
        },
        "id": "_ttJMY5y3nAJ"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install transformers bitsandbytes accelerate torch"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-07-18T12:51:02.948895Z",
          "iopub.execute_input": "2025-07-18T12:51:02.949206Z",
          "iopub.status.idle": "2025-07-18T12:51:06.244615Z",
          "shell.execute_reply.started": "2025-07-18T12:51:02.949178Z",
          "shell.execute_reply": "2025-07-18T12:51:06.243903Z"
        },
        "id": "1tlrk92v3nAJ",
        "outputId": "1d1dcd6a-566f-41c4-9fce-36c75e916dd7"
      },
      "outputs": [
        {
          "name": "stdout",
          "text": "Requirement already satisfied: transformers in /usr/local/lib/python3.11/dist-packages (4.52.4)\nRequirement already satisfied: bitsandbytes in /usr/local/lib/python3.11/dist-packages (0.46.1)\nRequirement already satisfied: accelerate in /usr/local/lib/python3.11/dist-packages (1.8.1)\nRequirement already satisfied: torch in /usr/local/lib/python3.11/dist-packages (2.6.0+cu124)\nRequirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from transformers) (3.18.0)\nRequirement already satisfied: huggingface-hub<1.0,>=0.30.0 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.33.1)\nRequirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.11/dist-packages (from transformers) (1.26.4)\nRequirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from transformers) (24.2)\nRequirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from transformers) (6.0.2)\nRequirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.11/dist-packages (from transformers) (2024.11.6)\nRequirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from transformers) (2.32.4)\nRequirement already satisfied: tokenizers<0.22,>=0.21 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.21.2)\nRequirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.5.3)\nRequirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.11/dist-packages (from transformers) (4.67.1)\nRequirement already satisfied: psutil in /usr/local/lib/python3.11/dist-packages (from accelerate) (7.0.0)\nRequirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.11/dist-packages (from torch) (4.14.0)\nRequirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch) (3.5)\nRequirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch) (3.1.6)\nRequirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch) (2025.5.1)\nRequirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\nRequirement already satisfied: nvidia-cuda-runtime-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\nRequirement already satisfied: nvidia-cuda-cupti-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\nRequirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /usr/local/lib/python3.11/dist-packages (from torch) (9.1.0.70)\nRequirement already satisfied: nvidia-cublas-cu12==12.4.5.8 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.5.8)\nRequirement already satisfied: nvidia-cufft-cu12==11.2.1.3 in /usr/local/lib/python3.11/dist-packages (from torch) (11.2.1.3)\nRequirement already satisfied: nvidia-curand-cu12==10.3.5.147 in /usr/local/lib/python3.11/dist-packages (from torch) (10.3.5.147)\nRequirement already satisfied: nvidia-cusolver-cu12==11.6.1.9 in /usr/local/lib/python3.11/dist-packages (from torch) (11.6.1.9)\nRequirement already satisfied: nvidia-cusparse-cu12==12.3.1.170 in /usr/local/lib/python3.11/dist-packages (from torch) (12.3.1.170)\nRequirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch) (0.6.2)\nRequirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch) (2.21.5)\nRequirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\nRequirement already satisfied: nvidia-nvjitlink-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\nRequirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch) (3.2.0)\nRequirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch) (1.13.1)\nRequirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch) (1.3.0)\nRequirement already satisfied: hf-xet<2.0.0,>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.30.0->transformers) (1.1.5)\nRequirement already satisfied: mkl_fft in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->transformers) (1.3.8)\nRequirement already satisfied: mkl_random in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->transformers) (1.2.4)\nRequirement already satisfied: mkl_umath in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->transformers) (0.1.1)\nRequirement already satisfied: mkl in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->transformers) (2025.2.0)\nRequirement already satisfied: tbb4py in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->transformers) (2022.2.0)\nRequirement already satisfied: mkl-service in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->transformers) (2.4.1)\nRequirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch) (3.0.2)\nRequirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (3.4.2)\nRequirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (3.10)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (2.5.0)\nRequirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (2025.6.15)\nRequirement already satisfied: intel-openmp<2026,>=2024 in /usr/local/lib/python3.11/dist-packages (from mkl->numpy>=1.17->transformers) (2024.2.0)\nRequirement already satisfied: tbb==2022.* in /usr/local/lib/python3.11/dist-packages (from mkl->numpy>=1.17->transformers) (2022.2.0)\nRequirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.11/dist-packages (from tbb==2022.*->mkl->numpy>=1.17->transformers) (1.4.0)\nRequirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.11/dist-packages (from mkl_umath->numpy>=1.17->transformers) (2024.2.0)\nRequirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.11/dist-packages (from intel-openmp<2026,>=2024->mkl->numpy>=1.17->transformers) (2024.2.0)\n",
          "output_type": "stream"
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "from huggingface_hub import hf_hub_download\n",
        "\n",
        "model_name = \"TheBloke/Mistral-7B-v0.1-GGUF\"  # note the “GGUF”\n",
        "model_file = \"mistral-7b-v0.1.Q4_K_M.gguf\"   # note the extension “.gguf”\n",
        "\n",
        "model_path = hf_hub_download(repo_id=model_name, filename=model_file)\n"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-07-18T12:51:41.554745Z",
          "iopub.execute_input": "2025-07-18T12:51:41.555519Z",
          "iopub.status.idle": "2025-07-18T12:51:58.464801Z",
          "shell.execute_reply.started": "2025-07-18T12:51:41.555489Z",
          "shell.execute_reply": "2025-07-18T12:51:58.464033Z"
        },
        "id": "FMr5SxUk3nAK",
        "outputId": "cef472c9-8e38-40d6-fa7b-d62145ddc3d7",
        "colab": {
          "referenced_widgets": [
            "1913bb6aa90a42aaa4295b5b81cca66b"
          ]
        }
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "mistral-7b-v0.1.Q4_K_M.gguf:   0%|          | 0.00/4.37G [00:00<?, ?B/s]",
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "1913bb6aa90a42aaa4295b5b81cca66b"
            }
          },
          "metadata": {}
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install langchain langchain-community"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-07-18T12:52:06.331333Z",
          "iopub.execute_input": "2025-07-18T12:52:06.331863Z",
          "iopub.status.idle": "2025-07-18T12:52:16.27994Z",
          "shell.execute_reply.started": "2025-07-18T12:52:06.331836Z",
          "shell.execute_reply": "2025-07-18T12:52:16.279151Z"
        },
        "id": "gyEm4VeE3nAK",
        "outputId": "ccc160e0-d1a7-4449-8498-eff5807404e7"
      },
      "outputs": [
        {
          "name": "stdout",
          "text": "Requirement already satisfied: langchain in /usr/local/lib/python3.11/dist-packages (0.3.26)\nCollecting langchain-community\n  Downloading langchain_community-0.3.27-py3-none-any.whl.metadata (2.9 kB)\nRequirement already satisfied: langchain-core<1.0.0,>=0.3.66 in /usr/local/lib/python3.11/dist-packages (from langchain) (0.3.66)\nRequirement already satisfied: langchain-text-splitters<1.0.0,>=0.3.8 in /usr/local/lib/python3.11/dist-packages (from langchain) (0.3.8)\nRequirement already satisfied: langsmith>=0.1.17 in /usr/local/lib/python3.11/dist-packages (from langchain) (0.4.1)\nRequirement already satisfied: pydantic<3.0.0,>=2.7.4 in /usr/local/lib/python3.11/dist-packages (from langchain) (2.11.7)\nRequirement already satisfied: SQLAlchemy<3,>=1.4 in /usr/local/lib/python3.11/dist-packages (from langchain) (2.0.41)\nRequirement already satisfied: requests<3,>=2 in /usr/local/lib/python3.11/dist-packages (from langchain) (2.32.4)\nRequirement already satisfied: PyYAML>=5.3 in /usr/local/lib/python3.11/dist-packages (from langchain) (6.0.2)\nRequirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /usr/local/lib/python3.11/dist-packages (from langchain-community) (3.12.13)\nRequirement already satisfied: tenacity!=8.4.0,<10,>=8.1.0 in /usr/local/lib/python3.11/dist-packages (from langchain-community) (8.5.0)\nRequirement already satisfied: dataclasses-json<0.7,>=0.5.7 in /usr/local/lib/python3.11/dist-packages (from langchain-community) (0.6.7)\nCollecting pydantic-settings<3.0.0,>=2.4.0 (from langchain-community)\n  Downloading pydantic_settings-2.10.1-py3-none-any.whl.metadata (3.4 kB)\nCollecting httpx-sse<1.0.0,>=0.4.0 (from langchain-community)\n  Downloading httpx_sse-0.4.1-py3-none-any.whl.metadata (9.4 kB)\nRequirement already satisfied: numpy>=1.26.2 in /usr/local/lib/python3.11/dist-packages (from langchain-community) (1.26.4)\nRequirement already satisfied: aiohappyeyeballs>=2.5.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (2.6.1)\nRequirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (1.3.2)\nRequirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (25.3.0)\nRequirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (1.7.0)\nRequirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (6.6.3)\nRequirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (0.3.2)\nRequirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (1.20.1)\nRequirement already satisfied: marshmallow<4.0.0,>=3.18.0 in /usr/local/lib/python3.11/dist-packages (from dataclasses-json<0.7,>=0.5.7->langchain-community) (3.26.1)\nRequirement already satisfied: typing-inspect<1,>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from dataclasses-json<0.7,>=0.5.7->langchain-community) (0.9.0)\nRequirement already satisfied: jsonpatch<2.0,>=1.33 in /usr/local/lib/python3.11/dist-packages (from langchain-core<1.0.0,>=0.3.66->langchain) (1.33)\nRequirement already satisfied: packaging<25,>=23.2 in /usr/local/lib/python3.11/dist-packages (from langchain-core<1.0.0,>=0.3.66->langchain) (24.2)\nRequirement already satisfied: typing-extensions>=4.7 in /usr/local/lib/python3.11/dist-packages (from langchain-core<1.0.0,>=0.3.66->langchain) (4.14.0)\nRequirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from langsmith>=0.1.17->langchain) (0.28.1)\nRequirement already satisfied: orjson<4.0.0,>=3.9.14 in /usr/local/lib/python3.11/dist-packages (from langsmith>=0.1.17->langchain) (3.10.18)\nRequirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from langsmith>=0.1.17->langchain) (1.0.0)\nRequirement already satisfied: zstandard<0.24.0,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from langsmith>=0.1.17->langchain) (0.23.0)\nRequirement already satisfied: mkl_fft in /usr/local/lib/python3.11/dist-packages (from numpy>=1.26.2->langchain-community) (1.3.8)\nRequirement already satisfied: mkl_random in /usr/local/lib/python3.11/dist-packages (from numpy>=1.26.2->langchain-community) (1.2.4)\nRequirement already satisfied: mkl_umath in /usr/local/lib/python3.11/dist-packages (from numpy>=1.26.2->langchain-community) (0.1.1)\nRequirement already satisfied: mkl in /usr/local/lib/python3.11/dist-packages (from numpy>=1.26.2->langchain-community) (2025.2.0)\nRequirement already satisfied: tbb4py in /usr/local/lib/python3.11/dist-packages (from numpy>=1.26.2->langchain-community) (2022.2.0)\nRequirement already satisfied: mkl-service in /usr/local/lib/python3.11/dist-packages (from numpy>=1.26.2->langchain-community) (2.4.1)\nRequirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain) (0.7.0)\nRequirement already satisfied: pydantic-core==2.33.2 in /usr/local/lib/python3.11/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain) (2.33.2)\nRequirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain) (0.4.1)\nCollecting python-dotenv>=0.21.0 (from pydantic-settings<3.0.0,>=2.4.0->langchain-community)\n  Downloading python_dotenv-1.1.1-py3-none-any.whl.metadata (24 kB)\nRequirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2->langchain) (3.4.2)\nRequirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2->langchain) (3.10)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2->langchain) (2.5.0)\nRequirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2->langchain) (2025.6.15)\nRequirement already satisfied: greenlet>=1 in /usr/local/lib/python3.11/dist-packages (from SQLAlchemy<3,>=1.4->langchain) (3.2.3)\nRequirement already satisfied: anyio in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.23.0->langsmith>=0.1.17->langchain) (4.9.0)\nRequirement already satisfied: httpcore==1.* in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.23.0->langsmith>=0.1.17->langchain) (1.0.9)\nRequirement already satisfied: h11>=0.16 in /usr/local/lib/python3.11/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->langsmith>=0.1.17->langchain) (0.16.0)\nRequirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.11/dist-packages (from jsonpatch<2.0,>=1.33->langchain-core<1.0.0,>=0.3.66->langchain) (3.0.0)\nRequirement already satisfied: mypy-extensions>=0.3.0 in /usr/local/lib/python3.11/dist-packages (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.5.7->langchain-community) (1.1.0)\nRequirement already satisfied: intel-openmp<2026,>=2024 in /usr/local/lib/python3.11/dist-packages (from mkl->numpy>=1.26.2->langchain-community) (2024.2.0)\nRequirement already satisfied: tbb==2022.* in /usr/local/lib/python3.11/dist-packages (from mkl->numpy>=1.26.2->langchain-community) (2022.2.0)\nRequirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.11/dist-packages (from tbb==2022.*->mkl->numpy>=1.26.2->langchain-community) (1.4.0)\nRequirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.11/dist-packages (from mkl_umath->numpy>=1.26.2->langchain-community) (2024.2.0)\nRequirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.11/dist-packages (from intel-openmp<2026,>=2024->mkl->numpy>=1.26.2->langchain-community) (2024.2.0)\nRequirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.11/dist-packages (from anyio->httpx<1,>=0.23.0->langsmith>=0.1.17->langchain) (1.3.1)\nDownloading langchain_community-0.3.27-py3-none-any.whl (2.5 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.5/2.5 MB\u001b[0m \u001b[31m31.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading httpx_sse-0.4.1-py3-none-any.whl (8.1 kB)\nDownloading pydantic_settings-2.10.1-py3-none-any.whl (45 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m45.2/45.2 kB\u001b[0m \u001b[31m2.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading python_dotenv-1.1.1-py3-none-any.whl (20 kB)\nInstalling collected packages: python-dotenv, httpx-sse, pydantic-settings, langchain-community\nSuccessfully installed httpx-sse-0.4.1 langchain-community-0.3.27 pydantic-settings-2.10.1 python-dotenv-1.1.1\n",
          "output_type": "stream"
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install llama-cpp-python"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-07-18T12:52:16.281526Z",
          "iopub.execute_input": "2025-07-18T12:52:16.281793Z",
          "iopub.status.idle": "2025-07-18T12:54:17.406218Z",
          "shell.execute_reply.started": "2025-07-18T12:52:16.281758Z",
          "shell.execute_reply": "2025-07-18T12:54:17.405259Z"
        },
        "id": "HaL5WBFh3nAL",
        "outputId": "99032692-2092-40ac-ea0c-5f62eb06d442"
      },
      "outputs": [
        {
          "name": "stdout",
          "text": "Collecting llama-cpp-python\n  Downloading llama_cpp_python-0.3.13.tar.gz (50.1 MB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m50.1/50.1 MB\u001b[0m \u001b[31m33.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n  Installing backend dependencies ... \u001b[?25l\u001b[?25hdone\n  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\nRequirement already satisfied: typing-extensions>=4.5.0 in /usr/local/lib/python3.11/dist-packages (from llama-cpp-python) (4.14.0)\nRequirement already satisfied: numpy>=1.20.0 in /usr/local/lib/python3.11/dist-packages (from llama-cpp-python) (1.26.4)\nCollecting diskcache>=5.6.1 (from llama-cpp-python)\n  Downloading diskcache-5.6.3-py3-none-any.whl.metadata (20 kB)\nRequirement already satisfied: jinja2>=2.11.3 in /usr/local/lib/python3.11/dist-packages (from llama-cpp-python) (3.1.6)\nRequirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2>=2.11.3->llama-cpp-python) (3.0.2)\nRequirement already satisfied: mkl_fft in /usr/local/lib/python3.11/dist-packages (from numpy>=1.20.0->llama-cpp-python) (1.3.8)\nRequirement already satisfied: mkl_random in /usr/local/lib/python3.11/dist-packages (from numpy>=1.20.0->llama-cpp-python) (1.2.4)\nRequirement already satisfied: mkl_umath in /usr/local/lib/python3.11/dist-packages (from numpy>=1.20.0->llama-cpp-python) (0.1.1)\nRequirement already satisfied: mkl in /usr/local/lib/python3.11/dist-packages (from numpy>=1.20.0->llama-cpp-python) (2025.2.0)\nRequirement already satisfied: tbb4py in /usr/local/lib/python3.11/dist-packages (from numpy>=1.20.0->llama-cpp-python) (2022.2.0)\nRequirement already satisfied: mkl-service in /usr/local/lib/python3.11/dist-packages (from numpy>=1.20.0->llama-cpp-python) (2.4.1)\nRequirement already satisfied: intel-openmp<2026,>=2024 in /usr/local/lib/python3.11/dist-packages (from mkl->numpy>=1.20.0->llama-cpp-python) (2024.2.0)\nRequirement already satisfied: tbb==2022.* in /usr/local/lib/python3.11/dist-packages (from mkl->numpy>=1.20.0->llama-cpp-python) (2022.2.0)\nRequirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.11/dist-packages (from tbb==2022.*->mkl->numpy>=1.20.0->llama-cpp-python) (1.4.0)\nRequirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.11/dist-packages (from mkl_umath->numpy>=1.20.0->llama-cpp-python) (2024.2.0)\nRequirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.11/dist-packages (from intel-openmp<2026,>=2024->mkl->numpy>=1.20.0->llama-cpp-python) (2024.2.0)\nDownloading diskcache-5.6.3-py3-none-any.whl (45 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m45.5/45.5 kB\u001b[0m \u001b[31m2.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hBuilding wheels for collected packages: llama-cpp-python\n  Building wheel for llama-cpp-python (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n  Created wheel for llama-cpp-python: filename=llama_cpp_python-0.3.13-cp311-cp311-linux_x86_64.whl size=4256230 sha256=86039a22e53b7121c9b825c359d9ac8e12f1e84da7d1ac9306acd3b9a71d2b2c\n  Stored in directory: /root/.cache/pip/wheels/90/6f/69/0760a999cdf90aacd874c03176ef0fd39a00642c82b4460397\nSuccessfully built llama-cpp-python\nInstalling collected packages: diskcache, llama-cpp-python\nSuccessfully installed diskcache-5.6.3 llama-cpp-python-0.3.13\n",
          "output_type": "stream"
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_community.llms import LlamaCpp\n",
        "from langchain_core.callbacks import CallbackManager, StreamingStdOutCallbackHandler\n",
        "llm = LlamaCpp(\n",
        "    model_path=model_path,\n",
        "    callback_manager=CallbackManager([StreamingStdOutCallbackHandler()]),\n",
        "    verbose=True,\n",
        "    n_gpu_layers=1,\n",
        "    n_batch=512,\n",
        "    n_ctx=2048,\n",
        "    f16_kv=True,\n",
        "    temperature=0.7,\n",
        "    max_tokens=1024,\n",
        ")"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-07-18T12:54:17.407402Z",
          "iopub.execute_input": "2025-07-18T12:54:17.40773Z",
          "iopub.status.idle": "2025-07-18T12:54:22.505253Z",
          "shell.execute_reply.started": "2025-07-18T12:54:17.407687Z",
          "shell.execute_reply": "2025-07-18T12:54:22.504427Z"
        },
        "id": "jEbHm1Tf3nAL",
        "outputId": "a52fcabb-a08a-4f88-a093-cc94681fcc41"
      },
      "outputs": [
        {
          "name": "stderr",
          "text": "llama_model_loader: loaded meta data with 20 key-value pairs and 291 tensors from /root/.cache/huggingface/hub/models--TheBloke--Mistral-7B-v0.1-GGUF/snapshots/d4ae605152c8de0d6570cf624c083fa57dd0d551/mistral-7b-v0.1.Q4_K_M.gguf (version GGUF V2)\nllama_model_loader: Dumping metadata keys/values. Note: KV overrides do not apply in this output.\nllama_model_loader: - kv   0:                       general.architecture str              = llama\nllama_model_loader: - kv   1:                               general.name str              = mistralai_mistral-7b-v0.1\nllama_model_loader: - kv   2:                       llama.context_length u32              = 32768\nllama_model_loader: - kv   3:                     llama.embedding_length u32              = 4096\nllama_model_loader: - kv   4:                          llama.block_count u32              = 32\nllama_model_loader: - kv   5:                  llama.feed_forward_length u32              = 14336\nllama_model_loader: - kv   6:                 llama.rope.dimension_count u32              = 128\nllama_model_loader: - kv   7:                 llama.attention.head_count u32              = 32\nllama_model_loader: - kv   8:              llama.attention.head_count_kv u32              = 8\nllama_model_loader: - kv   9:     llama.attention.layer_norm_rms_epsilon f32              = 0.000010\nllama_model_loader: - kv  10:                       llama.rope.freq_base f32              = 10000.000000\nllama_model_loader: - kv  11:                          general.file_type u32              = 15\nllama_model_loader: - kv  12:                       tokenizer.ggml.model str              = llama\nllama_model_loader: - kv  13:                      tokenizer.ggml.tokens arr[str,32000]   = [\"<unk>\", \"<s>\", \"</s>\", \"<0x00>\", \"<...\nllama_model_loader: - kv  14:                      tokenizer.ggml.scores arr[f32,32000]   = [0.000000, 0.000000, 0.000000, 0.0000...\nllama_model_loader: - kv  15:                  tokenizer.ggml.token_type arr[i32,32000]   = [2, 3, 3, 6, 6, 6, 6, 6, 6, 6, 6, 6, ...\nllama_model_loader: - kv  16:                tokenizer.ggml.bos_token_id u32              = 1\nllama_model_loader: - kv  17:                tokenizer.ggml.eos_token_id u32              = 2\nllama_model_loader: - kv  18:            tokenizer.ggml.unknown_token_id u32              = 0\nllama_model_loader: - kv  19:               general.quantization_version u32              = 2\nllama_model_loader: - type  f32:   65 tensors\nllama_model_loader: - type q4_K:  193 tensors\nllama_model_loader: - type q6_K:   33 tensors\nprint_info: file format = GGUF V2\nprint_info: file type   = Q4_K - Medium\nprint_info: file size   = 4.07 GiB (4.83 BPW) \ninit_tokenizer: initializing tokenizer for type 1\nload: control token:      2 '</s>' is not marked as EOG\nload: control token:      1 '<s>' is not marked as EOG\nload: special_eos_id is not in special_eog_ids - the tokenizer config may be incorrect\nload: special tokens cache size = 3\nload: token to piece cache size = 0.1637 MB\nprint_info: arch             = llama\nprint_info: vocab_only       = 0\nprint_info: n_ctx_train      = 32768\nprint_info: n_embd           = 4096\nprint_info: n_layer          = 32\nprint_info: n_head           = 32\nprint_info: n_head_kv        = 8\nprint_info: n_rot            = 128\nprint_info: n_swa            = 0\nprint_info: is_swa_any       = 0\nprint_info: n_embd_head_k    = 128\nprint_info: n_embd_head_v    = 128\nprint_info: n_gqa            = 4\nprint_info: n_embd_k_gqa     = 1024\nprint_info: n_embd_v_gqa     = 1024\nprint_info: f_norm_eps       = 0.0e+00\nprint_info: f_norm_rms_eps   = 1.0e-05\nprint_info: f_clamp_kqv      = 0.0e+00\nprint_info: f_max_alibi_bias = 0.0e+00\nprint_info: f_logit_scale    = 0.0e+00\nprint_info: f_attn_scale     = 0.0e+00\nprint_info: n_ff             = 14336\nprint_info: n_expert         = 0\nprint_info: n_expert_used    = 0\nprint_info: causal attn      = 1\nprint_info: pooling type     = 0\nprint_info: rope type        = 0\nprint_info: rope scaling     = linear\nprint_info: freq_base_train  = 10000.0\nprint_info: freq_scale_train = 1\nprint_info: n_ctx_orig_yarn  = 32768\nprint_info: rope_finetuned   = unknown\nprint_info: model type       = 7B\nprint_info: model params     = 7.24 B\nprint_info: general.name     = mistralai_mistral-7b-v0.1\nprint_info: vocab type       = SPM\nprint_info: n_vocab          = 32000\nprint_info: n_merges         = 0\nprint_info: BOS token        = 1 '<s>'\nprint_info: EOS token        = 2 '</s>'\nprint_info: UNK token        = 0 '<unk>'\nprint_info: LF token         = 13 '<0x0A>'\nprint_info: EOG token        = 2 '</s>'\nprint_info: max token length = 48\nload_tensors: loading model tensors, this can take a while... (mmap = true)\nload_tensors: layer   0 assigned to device CPU, is_swa = 0\nload_tensors: layer   1 assigned to device CPU, is_swa = 0\nload_tensors: layer   2 assigned to device CPU, is_swa = 0\nload_tensors: layer   3 assigned to device CPU, is_swa = 0\nload_tensors: layer   4 assigned to device CPU, is_swa = 0\nload_tensors: layer   5 assigned to device CPU, is_swa = 0\nload_tensors: layer   6 assigned to device CPU, is_swa = 0\nload_tensors: layer   7 assigned to device CPU, is_swa = 0\nload_tensors: layer   8 assigned to device CPU, is_swa = 0\nload_tensors: layer   9 assigned to device CPU, is_swa = 0\nload_tensors: layer  10 assigned to device CPU, is_swa = 0\nload_tensors: layer  11 assigned to device CPU, is_swa = 0\nload_tensors: layer  12 assigned to device CPU, is_swa = 0\nload_tensors: layer  13 assigned to device CPU, is_swa = 0\nload_tensors: layer  14 assigned to device CPU, is_swa = 0\nload_tensors: layer  15 assigned to device CPU, is_swa = 0\nload_tensors: layer  16 assigned to device CPU, is_swa = 0\nload_tensors: layer  17 assigned to device CPU, is_swa = 0\nload_tensors: layer  18 assigned to device CPU, is_swa = 0\nload_tensors: layer  19 assigned to device CPU, is_swa = 0\nload_tensors: layer  20 assigned to device CPU, is_swa = 0\nload_tensors: layer  21 assigned to device CPU, is_swa = 0\nload_tensors: layer  22 assigned to device CPU, is_swa = 0\nload_tensors: layer  23 assigned to device CPU, is_swa = 0\nload_tensors: layer  24 assigned to device CPU, is_swa = 0\nload_tensors: layer  25 assigned to device CPU, is_swa = 0\nload_tensors: layer  26 assigned to device CPU, is_swa = 0\nload_tensors: layer  27 assigned to device CPU, is_swa = 0\nload_tensors: layer  28 assigned to device CPU, is_swa = 0\nload_tensors: layer  29 assigned to device CPU, is_swa = 0\nload_tensors: layer  30 assigned to device CPU, is_swa = 0\nload_tensors: layer  31 assigned to device CPU, is_swa = 0\nload_tensors: layer  32 assigned to device CPU, is_swa = 0\nload_tensors: tensor 'token_embd.weight' (q4_K) (and 98 others) cannot be used with preferred buffer type CPU_REPACK, using CPU instead\nload_tensors:   CPU_REPACK model buffer size =  3204.00 MiB\nload_tensors:   CPU_Mapped model buffer size =  4165.37 MiB\nrepack: repack tensor blk.0.attn_q.weight with q4_K_8x8\nrepack: repack tensor blk.0.attn_k.weight with q4_K_8x8\nrepack: repack tensor blk.0.attn_output.weight with q4_K_8x8\nrepack: repack tensor blk.0.ffn_gate.weight with q4_K_8x8\n.repack: repack tensor blk.0.ffn_up.weight with q4_K_8x8\nrepack: repack tensor blk.1.attn_q.weight with q4_K_8x8\n.repack: repack tensor blk.1.attn_k.weight with q4_K_8x8\nrepack: repack tensor blk.1.attn_output.weight with q4_K_8x8\nrepack: repack tensor blk.1.ffn_gate.weight with q4_K_8x8\n.repack: repack tensor blk.1.ffn_up.weight with q4_K_8x8\nrepack: repack tensor blk.2.attn_q.weight with q4_K_8x8\n.repack: repack tensor blk.2.attn_k.weight with q4_K_8x8\nrepack: repack tensor blk.2.attn_output.weight with q4_K_8x8\nrepack: repack tensor blk.2.ffn_gate.weight with q4_K_8x8\n.repack: repack tensor blk.2.ffn_up.weight with q4_K_8x8\nrepack: repack tensor blk.3.attn_q.weight with q4_K_8x8\n.repack: repack tensor blk.3.attn_k.weight with q4_K_8x8\nrepack: repack tensor blk.3.attn_output.weight with q4_K_8x8\nrepack: repack tensor blk.3.ffn_gate.weight with q4_K_8x8\n.repack: repack tensor blk.3.ffn_up.weight with q4_K_8x8\nrepack: repack tensor blk.4.attn_q.weight with q4_K_8x8\n.repack: repack tensor blk.4.attn_k.weight with q4_K_8x8\nrepack: repack tensor blk.4.attn_v.weight with q4_K_8x8\nrepack: repack tensor blk.4.attn_output.weight with q4_K_8x8\nrepack: repack tensor blk.4.ffn_gate.weight with q4_K_8x8\n.repack: repack tensor blk.4.ffn_down.weight with q4_K_8x8\n.repack: repack tensor blk.4.ffn_up.weight with q4_K_8x8\nrepack: repack tensor blk.5.attn_q.weight with q4_K_8x8\n.repack: repack tensor blk.5.attn_k.weight with q4_K_8x8\nrepack: repack tensor blk.5.attn_v.weight with q4_K_8x8\nrepack: repack tensor blk.5.attn_output.weight with q4_K_8x8\nrepack: repack tensor blk.5.ffn_gate.weight with q4_K_8x8\n.repack: repack tensor blk.5.ffn_down.weight with q4_K_8x8\nrepack: repack tensor blk.5.ffn_up.weight with q4_K_8x8\n.repack: repack tensor blk.6.attn_q.weight with q4_K_8x8\nrepack: repack tensor blk.6.attn_k.weight with q4_K_8x8\nrepack: repack tensor blk.6.attn_output.weight with q4_K_8x8\n.repack: repack tensor blk.6.ffn_gate.weight with q4_K_8x8\nrepack: repack tensor blk.6.ffn_up.weight with q4_K_8x8\n.repack: repack tensor blk.7.attn_q.weight with q4_K_8x8\nrepack: repack tensor blk.7.attn_k.weight with q4_K_8x8\nrepack: repack tensor blk.7.attn_v.weight with q4_K_8x8\nrepack: repack tensor blk.7.attn_output.weight with q4_K_8x8\n.repack: repack tensor blk.7.ffn_gate.weight with q4_K_8x8\nrepack: repack tensor blk.7.ffn_down.weight with q4_K_8x8\n.repack: repack tensor blk.7.ffn_up.weight with q4_K_8x8\n.repack: repack tensor blk.8.attn_q.weight with q4_K_8x8\nrepack: repack tensor blk.8.attn_k.weight with q4_K_8x8\nrepack: repack tensor blk.8.attn_v.weight with q4_K_8x8\nrepack: repack tensor blk.8.attn_output.weight with q4_K_8x8\nrepack: repack tensor blk.8.ffn_gate.weight with q4_K_8x8\n.repack: repack tensor blk.8.ffn_down.weight with q4_K_8x8\n.repack: repack tensor blk.8.ffn_up.weight with q4_K_8x8\n.repack: repack tensor blk.9.attn_q.weight with q4_K_8x8\nrepack: repack tensor blk.9.attn_k.weight with q4_K_8x8\nrepack: repack tensor blk.9.attn_output.weight with q4_K_8x8\nrepack: repack tensor blk.9.ffn_gate.weight with q4_K_8x8\n.repack: repack tensor blk.9.ffn_up.weight with q4_K_8x8\n.repack: repack tensor blk.10.attn_q.weight with q4_K_8x8\nrepack: repack tensor blk.10.attn_k.weight with q4_K_8x8\nrepack: repack tensor blk.10.attn_v.weight with q4_K_8x8\nrepack: repack tensor blk.10.attn_output.weight with q4_K_8x8\nrepack: repack tensor blk.10.ffn_gate.weight with q4_K_8x8\n.repack: repack tensor blk.10.ffn_down.weight with q4_K_8x8\n.repack: repack tensor blk.10.ffn_up.weight with q4_K_8x8\n.repack: repack tensor blk.11.attn_q.weight with q4_K_8x8\nrepack: repack tensor blk.11.attn_k.weight with q4_K_8x8\nrepack: repack tensor blk.11.attn_v.weight with q4_K_8x8\nrepack: repack tensor blk.11.attn_output.weight with q4_K_8x8\nrepack: repack tensor blk.11.ffn_gate.weight with q4_K_8x8\n.repack: repack tensor blk.11.ffn_down.weight with q4_K_8x8\n.repack: repack tensor blk.11.ffn_up.weight with q4_K_8x8\nrepack: repack tensor blk.12.attn_q.weight with q4_K_8x8\n.repack: repack tensor blk.12.attn_k.weight with q4_K_8x8\nrepack: repack tensor blk.12.attn_output.weight with q4_K_8x8\nrepack: repack tensor blk.12.ffn_gate.weight with q4_K_8x8\n.repack: repack tensor blk.12.ffn_up.weight with q4_K_8x8\nrepack: repack tensor blk.13.attn_q.weight with q4_K_8x8\n.repack: repack tensor blk.13.attn_k.weight with q4_K_8x8\nrepack: repack tensor blk.13.attn_v.weight with q4_K_8x8\nrepack: repack tensor blk.13.attn_output.weight with q4_K_8x8\nrepack: repack tensor blk.13.ffn_gate.weight with q4_K_8x8\n.repack: repack tensor blk.13.ffn_down.weight with q4_K_8x8\nrepack: repack tensor blk.13.ffn_up.weight with q4_K_8x8\n.repack: repack tensor blk.14.attn_q.weight with q4_K_8x8\nrepack: repack tensor blk.14.attn_k.weight with q4_K_8x8\nrepack: repack tensor blk.14.attn_v.weight with q4_K_8x8\nrepack: repack tensor blk.14.attn_output.weight with q4_K_8x8\n.repack: repack tensor blk.14.ffn_gate.weight with q4_K_8x8\nrepack: repack tensor blk.14.ffn_down.weight with q4_K_8x8\n.repack: repack tensor blk.14.ffn_up.weight with q4_K_8x8\n.repack: repack tensor blk.15.attn_q.weight with q4_K_8x8\nrepack: repack tensor blk.15.attn_k.weight with q4_K_8x8\nrepack: repack tensor blk.15.attn_output.weight with q4_K_8x8\nrepack: repack tensor blk.15.ffn_gate.weight with q4_K_8x8\n.repack: repack tensor blk.15.ffn_up.weight with q4_K_8x8\n.repack: repack tensor blk.16.attn_q.weight with q4_K_8x8\nrepack: repack tensor blk.16.attn_k.weight with q4_K_8x8\nrepack: repack tensor blk.16.attn_v.weight with q4_K_8x8\nrepack: repack tensor blk.16.attn_output.weight with q4_K_8x8\n.repack: repack tensor blk.16.ffn_gate.weight with q4_K_8x8\nrepack: repack tensor blk.16.ffn_down.weight with q4_K_8x8\n.repack: repack tensor blk.16.ffn_up.weight with q4_K_8x8\n.repack: repack tensor blk.17.attn_q.weight with q4_K_8x8\nrepack: repack tensor blk.17.attn_k.weight with q4_K_8x8\nrepack: repack tensor blk.17.attn_v.weight with q4_K_8x8\nrepack: repack tensor blk.17.attn_output.weight with q4_K_8x8\nrepack: repack tensor blk.17.ffn_gate.weight with q4_K_8x8\n.repack: repack tensor blk.17.ffn_down.weight with q4_K_8x8\n.repack: repack tensor blk.17.ffn_up.weight with q4_K_8x8\n.repack: repack tensor blk.18.attn_q.weight with q4_K_8x8\nrepack: repack tensor blk.18.attn_k.weight with q4_K_8x8\nrepack: repack tensor blk.18.attn_output.weight with q4_K_8x8\nrepack: repack tensor blk.18.ffn_gate.weight with q4_K_8x8\n.repack: repack tensor blk.18.ffn_up.weight with q4_K_8x8\n.repack: repack tensor blk.19.attn_q.weight with q4_K_8x8\nrepack: repack tensor blk.19.attn_k.weight with q4_K_8x8\nrepack: repack tensor blk.19.attn_v.weight with q4_K_8x8\nrepack: repack tensor blk.19.attn_output.weight with q4_K_8x8\nrepack: repack tensor blk.19.ffn_gate.weight with q4_K_8x8\n.repack: repack tensor blk.19.ffn_down.weight with q4_K_8x8\n.repack: repack tensor blk.19.ffn_up.weight with q4_K_8x8\nrepack: repack tensor blk.20.attn_q.weight with q4_K_8x8\n.repack: repack tensor blk.20.attn_k.weight with q4_K_8x8\nrepack: repack tensor blk.20.attn_v.weight with q4_K_8x8\nrepack: repack tensor blk.20.attn_output.weight with q4_K_8x8\nrepack: repack tensor blk.20.ffn_gate.weight with q4_K_8x8\n.repack: repack tensor blk.20.ffn_down.weight with q4_K_8x8\nrepack: repack tensor blk.20.ffn_up.weight with q4_K_8x8\n.repack: repack tensor blk.21.attn_q.weight with q4_K_8x8\nrepack: repack tensor blk.21.attn_k.weight with q4_K_8x8\nrepack: repack tensor blk.21.attn_output.weight with q4_K_8x8\n.repack: repack tensor blk.21.ffn_gate.weight with q4_K_8x8\nrepack: repack tensor blk.21.ffn_up.weight with q4_K_8x8\n.repack: repack tensor blk.22.attn_q.weight with q4_K_8x8\nrepack: repack tensor blk.22.attn_k.weight with q4_K_8x8\nrepack: repack tensor blk.22.attn_v.weight with q4_K_8x8\n.repack: repack tensor blk.22.attn_output.weight with q4_K_8x8\nrepack: repack tensor blk.22.ffn_gate.weight with q4_K_8x8\nrepack: repack tensor blk.22.ffn_down.weight with q4_K_8x8\n.repack: repack tensor blk.22.ffn_up.weight with q4_K_8x8\n.repack: repack tensor blk.23.attn_q.weight with q4_K_8x8\nrepack: repack tensor blk.23.attn_k.weight with q4_K_8x8\nrepack: repack tensor blk.23.attn_v.weight with q4_K_8x8\nrepack: repack tensor blk.23.attn_output.weight with q4_K_8x8\n.repack: repack tensor blk.23.ffn_gate.weight with q4_K_8x8\nrepack: repack tensor blk.23.ffn_down.weight with q4_K_8x8\n.repack: repack tensor blk.23.ffn_up.weight with q4_K_8x8\n.repack: repack tensor blk.24.attn_q.weight with q4_K_8x8\nrepack: repack tensor blk.24.attn_k.weight with q4_K_8x8\nrepack: repack tensor blk.24.attn_output.weight with q4_K_8x8\nrepack: repack tensor blk.24.ffn_gate.weight with q4_K_8x8\n.repack: repack tensor blk.24.ffn_up.weight with q4_K_8x8\n.repack: repack tensor blk.25.attn_q.weight with q4_K_8x8\nrepack: repack tensor blk.25.attn_k.weight with q4_K_8x8\nrepack: repack tensor blk.25.attn_v.weight with q4_K_8x8\nrepack: repack tensor blk.25.attn_output.weight with q4_K_8x8\nrepack: repack tensor blk.25.ffn_gate.weight with q4_K_8x8\n.repack: repack tensor blk.25.ffn_down.weight with q4_K_8x8\n.repack: repack tensor blk.25.ffn_up.weight with q4_K_8x8\n.repack: repack tensor blk.26.attn_q.weight with q4_K_8x8\nrepack: repack tensor blk.26.attn_k.weight with q4_K_8x8\nrepack: repack tensor blk.26.attn_v.weight with q4_K_8x8\nrepack: repack tensor blk.26.attn_output.weight with q4_K_8x8\nrepack: repack tensor blk.26.ffn_gate.weight with q4_K_8x8\n.repack: repack tensor blk.26.ffn_down.weight with q4_K_8x8\n.repack: repack tensor blk.26.ffn_up.weight with q4_K_8x8\nrepack: repack tensor blk.27.attn_q.weight with q4_K_8x8\n.repack: repack tensor blk.27.attn_k.weight with q4_K_8x8\nrepack: repack tensor blk.27.attn_output.weight with q4_K_8x8\nrepack: repack tensor blk.27.ffn_gate.weight with q4_K_8x8\n.repack: repack tensor blk.27.ffn_up.weight with q4_K_8x8\nrepack: repack tensor blk.28.attn_q.weight with q4_K_8x8\n.repack: repack tensor blk.28.attn_k.weight with q4_K_8x8\nrepack: repack tensor blk.28.attn_output.weight with q4_K_8x8\nrepack: repack tensor blk.28.ffn_gate.weight with q4_K_8x8\n.repack: repack tensor blk.28.ffn_up.weight with q4_K_8x8\nrepack: repack tensor blk.29.attn_q.weight with q4_K_8x8\n.repack: repack tensor blk.29.attn_k.weight with q4_K_8x8\nrepack: repack tensor blk.29.attn_output.weight with q4_K_8x8\nrepack: repack tensor blk.29.ffn_gate.weight with q4_K_8x8\n.repack: repack tensor blk.29.ffn_up.weight with q4_K_8x8\nrepack: repack tensor blk.30.attn_q.weight with q4_K_8x8\n.repack: repack tensor blk.30.attn_k.weight with q4_K_8x8\nrepack: repack tensor blk.30.attn_output.weight with q4_K_8x8\nrepack: repack tensor blk.30.ffn_gate.weight with q4_K_8x8\n.repack: repack tensor blk.30.ffn_up.weight with q4_K_8x8\nrepack: repack tensor blk.31.attn_q.weight with q4_K_8x8\n.repack: repack tensor blk.31.attn_k.weight with q4_K_8x8\nrepack: repack tensor blk.31.attn_output.weight with q4_K_8x8\nrepack: repack tensor blk.31.ffn_gate.weight with q4_K_8x8\n.repack: repack tensor blk.31.ffn_up.weight with q4_K_8x8\n...................\nllama_context: constructing llama_context\nllama_context: n_seq_max     = 1\nllama_context: n_ctx         = 2048\nllama_context: n_ctx_per_seq = 2048\nllama_context: n_batch       = 512\nllama_context: n_ubatch      = 512\nllama_context: causal_attn   = 1\nllama_context: flash_attn    = 0\nllama_context: freq_base     = 10000.0\nllama_context: freq_scale    = 1\nllama_context: n_ctx_per_seq (2048) < n_ctx_train (32768) -- the full capacity of the model will not be utilized\nset_abort_callback: call\nllama_context:        CPU  output buffer size =     0.12 MiB\ncreate_memory: n_ctx = 2048 (padded)\nllama_kv_cache_unified: layer   0: dev = CPU\nllama_kv_cache_unified: layer   1: dev = CPU\nllama_kv_cache_unified: layer   2: dev = CPU\nllama_kv_cache_unified: layer   3: dev = CPU\nllama_kv_cache_unified: layer   4: dev = CPU\nllama_kv_cache_unified: layer   5: dev = CPU\nllama_kv_cache_unified: layer   6: dev = CPU\nllama_kv_cache_unified: layer   7: dev = CPU\nllama_kv_cache_unified: layer   8: dev = CPU\nllama_kv_cache_unified: layer   9: dev = CPU\nllama_kv_cache_unified: layer  10: dev = CPU\nllama_kv_cache_unified: layer  11: dev = CPU\nllama_kv_cache_unified: layer  12: dev = CPU\nllama_kv_cache_unified: layer  13: dev = CPU\nllama_kv_cache_unified: layer  14: dev = CPU\nllama_kv_cache_unified: layer  15: dev = CPU\nllama_kv_cache_unified: layer  16: dev = CPU\nllama_kv_cache_unified: layer  17: dev = CPU\nllama_kv_cache_unified: layer  18: dev = CPU\nllama_kv_cache_unified: layer  19: dev = CPU\nllama_kv_cache_unified: layer  20: dev = CPU\nllama_kv_cache_unified: layer  21: dev = CPU\nllama_kv_cache_unified: layer  22: dev = CPU\nllama_kv_cache_unified: layer  23: dev = CPU\nllama_kv_cache_unified: layer  24: dev = CPU\nllama_kv_cache_unified: layer  25: dev = CPU\nllama_kv_cache_unified: layer  26: dev = CPU\nllama_kv_cache_unified: layer  27: dev = CPU\nllama_kv_cache_unified: layer  28: dev = CPU\nllama_kv_cache_unified: layer  29: dev = CPU\nllama_kv_cache_unified: layer  30: dev = CPU\nllama_kv_cache_unified: layer  31: dev = CPU\nllama_kv_cache_unified:        CPU KV buffer size =   256.00 MiB\nllama_kv_cache_unified: size =  256.00 MiB (  2048 cells,  32 layers,  1 seqs), K (f16):  128.00 MiB, V (f16):  128.00 MiB\nllama_kv_cache_unified: LLAMA_SET_ROWS=0, using old ggml_cpy() method for backwards compatibility\nllama_context: enumerating backends\nllama_context: backend_ptrs.size() = 1\nllama_context: max_nodes = 65536\nllama_context: worst-case: n_tokens = 512, n_seqs = 1, n_outputs = 0\ngraph_reserve: reserving a graph for ubatch with n_tokens =  512, n_seqs =  1, n_outputs =  512\ngraph_reserve: reserving a graph for ubatch with n_tokens =    1, n_seqs =  1, n_outputs =    1\ngraph_reserve: reserving a graph for ubatch with n_tokens =  512, n_seqs =  1, n_outputs =  512\nllama_context:        CPU compute buffer size =   164.01 MiB\nllama_context: graph nodes  = 1158\nllama_context: graph splits = 1\nCPU : SSE3 = 1 | SSSE3 = 1 | AVX = 1 | AVX2 = 1 | F16C = 1 | FMA = 1 | BMI2 = 1 | AVX512 = 1 | LLAMAFILE = 1 | OPENMP = 1 | REPACK = 1 | \nModel metadata: {'tokenizer.ggml.unknown_token_id': '0', 'tokenizer.ggml.eos_token_id': '2', 'general.architecture': 'llama', 'llama.rope.freq_base': '10000.000000', 'llama.context_length': '32768', 'general.name': 'mistralai_mistral-7b-v0.1', 'llama.embedding_length': '4096', 'llama.feed_forward_length': '14336', 'llama.attention.layer_norm_rms_epsilon': '0.000010', 'llama.rope.dimension_count': '128', 'tokenizer.ggml.bos_token_id': '1', 'llama.attention.head_count': '32', 'llama.block_count': '32', 'llama.attention.head_count_kv': '8', 'general.quantization_version': '2', 'tokenizer.ggml.model': 'llama', 'general.file_type': '15'}\nUsing fallback chat format: llama-2\n",
          "output_type": "stream"
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "llm"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-07-18T12:54:22.506902Z",
          "iopub.execute_input": "2025-07-18T12:54:22.507249Z",
          "iopub.status.idle": "2025-07-18T12:54:22.512905Z",
          "shell.execute_reply.started": "2025-07-18T12:54:22.50723Z",
          "shell.execute_reply": "2025-07-18T12:54:22.512267Z"
        },
        "id": "nz61pmbh3nAL",
        "outputId": "2876ed10-80b1-41e3-a9e9-e6b8d3d7eb10"
      },
      "outputs": [
        {
          "execution_count": 11,
          "output_type": "execute_result",
          "data": {
            "text/plain": "LlamaCpp(callbacks=<langchain_core.callbacks.manager.CallbackManager object at 0x799255c4e090>, client=<llama_cpp.llama.Llama object at 0x79924ff96bd0>, model_path='/root/.cache/huggingface/hub/models--TheBloke--Mistral-7B-v0.1-GGUF/snapshots/d4ae605152c8de0d6570cf624c083fa57dd0d551/mistral-7b-v0.1.Q4_K_M.gguf', n_ctx=2048, n_batch=512, n_gpu_layers=1, max_tokens=1024, temperature=0.7, model_kwargs={})"
          },
          "metadata": {}
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "# Test the model\n",
        "response = llm.invoke(\"What is Machine Learning?\")\n",
        "print(response)"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-07-18T12:54:22.513599Z",
          "iopub.execute_input": "2025-07-18T12:54:22.513774Z",
          "iopub.status.idle": "2025-07-18T12:59:44.412129Z",
          "shell.execute_reply.started": "2025-07-18T12:54:22.51376Z",
          "shell.execute_reply": "2025-07-18T12:59:44.411449Z"
        },
        "id": "B4dHoMbK3nAM",
        "outputId": "07a94882-209b-4296-e544-81499bbad91e"
      },
      "outputs": [
        {
          "name": "stdout",
          "text": "\n\nMachine learning is a method of data analysis that automates analytical model building. It is a branch of artificial intelligence based on the idea that systems can learn from data, identify patterns and make decisions with minimal human intervention. Machine learning algorithms use statistical techniques to give computers the ability to “learn” (i.e., progressively improve performance) with data, without being explicitly programmed.\n\nMachine Learning Algorithms:\n\n1. Supervised Machine Learning: It is a type of machine learning algorithm in which the input data includes both input variables and desired output variables. It uses labeled historical data to classify objects or make predictions about future events. There are two types of supervised ML algorithms: classification and regression.\n- Classification Algorithms: Classification algorithms learn to categorize data into different groups. Common examples include logistic regression, naive bayes, random forest, support vector machines (SVMs), etc.\n- Regression Algorithms: In regression analysis, the goal is to predict a continuous outcome based on input variables. Regression models can be linear or nonlinear and include algorithms such as simple linear regression, multiple linear regression, k-nearest neighbors (KNN), polynomial regression, etc.\n2. Unsupervised Machine Learning: It is a type of machine learning algorithm that uses unlabeled data to discover patterns in data without relying on predefined labels or outcomes. Examples include clustering algorithms, which group similar observations together into clusters based on common characteristics; association rule mining, which finds relationships between variables within large datasets; and anomaly detection algorithms, which detect unusual events by comparing them against historical data.\n- Clustering Algorithms: These algorithms group similar observations together into clusters based on some distance measure or other criteria such as density or entropy. Examples include k-means clustering, hierarchical clustering and DBSCAN.\n- Association Rule Mining: This type of algorithm looks for interesting relationships between variables within large datasets by identifying frequent co-occurrences among them (e.g., if you buy diapers then you also tend to buy baby wipes). Examples include Apriori, FP-Growth and Eclat algorithms.\n3. Semi-Supervised Machine Learning: It is a machine learning method that uses both labeled and unlabeled data sets for training purposes. Semi-supervised learning can be useful when there is not enough labeled data available but still some amount of unlabeled data exists which could potentially provide helpful insights into the problem at hand if properly utilized during training process. Examples include co-training, self-training and graph based methods like transductive SVMs (TSVM).\n4. Reinforcement Learning: It is a type of machine learning algorithm where an agent learns how to maximize rewards by interacting with its environment over time through trial and error experiments until it finds optimal solutions or policies which maximize rewards while minimizing costs incurred during each action taken within given constraints set forth by problem statement itself.\n- Q-Learning: It is a reinforcement learning algorithm used primarily for solving Markov decision processes (MDPs). The goal here would be figuring out how best possible sequence of actions should be taken at every step so as to maximize cumulative reward received over time horizon considered here while keeping costs associated with each action within specified range set forth by problem statement itself.\n- Deep Q Networks: These are neural network based versions of classic Q-learning algorithms which use deep learning techniques such as convolutional neural networks (CNNs), recurrent neural networks (RNNs) etc., along with long short term memory cells (LSTMs) etc., so that they can learn complex decision making processes from large amounts data sets available today without requiring human intervention at any stage whatsoever.\n- Policy Gradient Methods: These are another class of algorithms used commonly within reinforcement learning domain which uses gradient descent type optimization methods along with policy iteration techniques such as actor-critic method etc., so that they can learn optimal policies or decision making processes over time horizon considered here without requiring any human intervention whatsoever.\n5. Natural Language Processing (NLP): It is an emerging field within machine learning domain which focuses on understanding natural language texts using computational techniques such as machine translation, sentiment analysis, part-of-speech tagging etc., so that machines can understand and respond intelligently to human queries posed by users in form of text messages sent via social media platforms like Facebook, Twitter etc., without requiring any human intervention at all.\n6. Deep Learning: It is a subfield within machine learning domain which uses deep neural networks (DNNs) along with backpropagation algorithm for training purpose so as to achieve better accuracy while performing certain complex tasks such as image classification, object detection etc., compared to conventional shallow machine learning algorithms like SVMs etc.,",
          "output_type": "stream"
        },
        {
          "name": "stderr",
          "text": "llama_perf_context_print:        load time =     875.09 ms\nllama_perf_context_print: prompt eval time =     874.94 ms /     6 tokens (  145.82 ms per token,     6.86 tokens per second)\nllama_perf_context_print:        eval time =  318364.04 ms /  1023 runs   (  311.21 ms per token,     3.21 tokens per second)\nllama_perf_context_print:       total time =  321830.21 ms /  1029 tokens\n",
          "output_type": "stream"
        },
        {
          "name": "stdout",
          "text": "\n\nMachine learning is a method of data analysis that automates analytical model building. It is a branch of artificial intelligence based on the idea that systems can learn from data, identify patterns and make decisions with minimal human intervention. Machine learning algorithms use statistical techniques to give computers the ability to “learn” (i.e., progressively improve performance) with data, without being explicitly programmed.\n\nMachine Learning Algorithms:\n\n1. Supervised Machine Learning: It is a type of machine learning algorithm in which the input data includes both input variables and desired output variables. It uses labeled historical data to classify objects or make predictions about future events. There are two types of supervised ML algorithms: classification and regression.\n- Classification Algorithms: Classification algorithms learn to categorize data into different groups. Common examples include logistic regression, naive bayes, random forest, support vector machines (SVMs), etc.\n- Regression Algorithms: In regression analysis, the goal is to predict a continuous outcome based on input variables. Regression models can be linear or nonlinear and include algorithms such as simple linear regression, multiple linear regression, k-nearest neighbors (KNN), polynomial regression, etc.\n2. Unsupervised Machine Learning: It is a type of machine learning algorithm that uses unlabeled data to discover patterns in data without relying on predefined labels or outcomes. Examples include clustering algorithms, which group similar observations together into clusters based on common characteristics; association rule mining, which finds relationships between variables within large datasets; and anomaly detection algorithms, which detect unusual events by comparing them against historical data.\n- Clustering Algorithms: These algorithms group similar observations together into clusters based on some distance measure or other criteria such as density or entropy. Examples include k-means clustering, hierarchical clustering and DBSCAN.\n- Association Rule Mining: This type of algorithm looks for interesting relationships between variables within large datasets by identifying frequent co-occurrences among them (e.g., if you buy diapers then you also tend to buy baby wipes). Examples include Apriori, FP-Growth and Eclat algorithms.\n3. Semi-Supervised Machine Learning: It is a machine learning method that uses both labeled and unlabeled data sets for training purposes. Semi-supervised learning can be useful when there is not enough labeled data available but still some amount of unlabeled data exists which could potentially provide helpful insights into the problem at hand if properly utilized during training process. Examples include co-training, self-training and graph based methods like transductive SVMs (TSVM).\n4. Reinforcement Learning: It is a type of machine learning algorithm where an agent learns how to maximize rewards by interacting with its environment over time through trial and error experiments until it finds optimal solutions or policies which maximize rewards while minimizing costs incurred during each action taken within given constraints set forth by problem statement itself.\n- Q-Learning: It is a reinforcement learning algorithm used primarily for solving Markov decision processes (MDPs). The goal here would be figuring out how best possible sequence of actions should be taken at every step so as to maximize cumulative reward received over time horizon considered here while keeping costs associated with each action within specified range set forth by problem statement itself.\n- Deep Q Networks: These are neural network based versions of classic Q-learning algorithms which use deep learning techniques such as convolutional neural networks (CNNs), recurrent neural networks (RNNs) etc., along with long short term memory cells (LSTMs) etc., so that they can learn complex decision making processes from large amounts data sets available today without requiring human intervention at any stage whatsoever.\n- Policy Gradient Methods: These are another class of algorithms used commonly within reinforcement learning domain which uses gradient descent type optimization methods along with policy iteration techniques such as actor-critic method etc., so that they can learn optimal policies or decision making processes over time horizon considered here without requiring any human intervention whatsoever.\n5. Natural Language Processing (NLP): It is an emerging field within machine learning domain which focuses on understanding natural language texts using computational techniques such as machine translation, sentiment analysis, part-of-speech tagging etc., so that machines can understand and respond intelligently to human queries posed by users in form of text messages sent via social media platforms like Facebook, Twitter etc., without requiring any human intervention at all.\n6. Deep Learning: It is a subfield within machine learning domain which uses deep neural networks (DNNs) along with backpropagation algorithm for training purpose so as to achieve better accuracy while performing certain complex tasks such as image classification, object detection etc., compared to conventional shallow machine learning algorithms like SVMs etc.,\n",
          "output_type": "stream"
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain import PromptTemplate, LLMChain\n",
        "\n",
        "question=\"Who won the Cricket World Cup in the year 2011?\"\n",
        "template = \"\"\"Question: {question}\n",
        "Answer: Let's think step by step.\"\"\"\n",
        "prompt = PromptTemplate(template=template, input_variables=[\"question\"])\n",
        "print(prompt)"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-07-18T12:59:44.413039Z",
          "iopub.execute_input": "2025-07-18T12:59:44.413296Z",
          "iopub.status.idle": "2025-07-18T12:59:44.525604Z",
          "shell.execute_reply.started": "2025-07-18T12:59:44.413267Z",
          "shell.execute_reply": "2025-07-18T12:59:44.525005Z"
        },
        "id": "MWEKO62Z3nAM",
        "outputId": "31dc5daf-0788-4ecc-a622-bc4af360af8e"
      },
      "outputs": [
        {
          "name": "stdout",
          "text": "input_variables=['question'] input_types={} partial_variables={} template=\"Question: {question}\\nAnswer: Let's think step by step.\"\n",
          "output_type": "stream"
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "llm_chain=LLMChain(llm=llm,prompt=prompt)\n",
        "print(llm_chain.invoke(question))"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-07-18T12:59:44.526272Z",
          "iopub.execute_input": "2025-07-18T12:59:44.52652Z",
          "iopub.status.idle": "2025-07-18T13:01:12.638496Z",
          "shell.execute_reply.started": "2025-07-18T12:59:44.526502Z",
          "shell.execute_reply": "2025-07-18T13:01:12.637823Z"
        },
        "id": "ssNVA74F3nAM",
        "outputId": "39020e7b-99bb-451b-8d3d-57ee5225ad25"
      },
      "outputs": [
        {
          "name": "stderr",
          "text": "/tmp/ipykernel_36/3919080688.py:1: LangChainDeprecationWarning: The class `LLMChain` was deprecated in LangChain 0.1.17 and will be removed in 1.0. Use :meth:`~RunnableSequence, e.g., `prompt | llm`` instead.\n  llm_chain=LLMChain(llm=llm,prompt=prompt)\nLlama.generate: 1 prefix-match hit, remaining 30 prompt tokens to eval\n",
          "output_type": "stream"
        },
        {
          "name": "stdout",
          "text": "\n1. Who won the Cricket World Cup in the year 2011?\nFirst, we have to know what is a Cricket World Cup. A Cricket World Cup (CWC) is an international cricket tournament organized by the International Cricket Council (ICC). The first ICC Cricket World Cup was held in England in 1975. Since then it has been organized every four years.\n2. Who won the Cricket World Cup in the year 2011?\nSecond, we have to know when the Cricket World Cup was held in the year 2011. The 2011 ICC Cricket World Cup began on 19 February with a match between India and Bangladesh at the Sher-e-Bangla National Stadium. The tournament final took place on 2 April 2011 at Wankhede Stadium in Mumbai, India.\n3. Who won the Cricket World Cup in the year 2011?\nThird, we have to know who won the Cricket World Cup in the year 2011. The final match was between India and Sri Lanka. India won the final by six wickets and became the World Champions for the second time in history after winning it previously in 1983.",
          "output_type": "stream"
        },
        {
          "name": "stderr",
          "text": "llama_perf_context_print:        load time =     875.09 ms\nllama_perf_context_print: prompt eval time =    3065.50 ms /    30 tokens (  102.18 ms per token,     9.79 tokens per second)\nllama_perf_context_print:        eval time =   84500.03 ms /   280 runs   (  301.79 ms per token,     3.31 tokens per second)\nllama_perf_context_print:       total time =   88103.17 ms /   310 tokens\n",
          "output_type": "stream"
        },
        {
          "name": "stdout",
          "text": "{'question': 'Who won the Cricket World Cup in the year 2011?', 'text': '\\n1. Who won the Cricket World Cup in the year 2011?\\nFirst, we have to know what is a Cricket World Cup. A Cricket World Cup (CWC) is an international cricket tournament organized by the International Cricket Council (ICC). The first ICC Cricket World Cup was held in England in 1975. Since then it has been organized every four years.\\n2. Who won the Cricket World Cup in the year 2011?\\nSecond, we have to know when the Cricket World Cup was held in the year 2011. The 2011 ICC Cricket World Cup began on 19 February with a match between India and Bangladesh at the Sher-e-Bangla National Stadium. The tournament final took place on 2 April 2011 at Wankhede Stadium in Mumbai, India.\\n3. Who won the Cricket World Cup in the year 2011?\\nThird, we have to know who won the Cricket World Cup in the year 2011. The final match was between India and Sri Lanka. India won the final by six wickets and became the World Champions for the second time in history after winning it previously in 1983.'}\n",
          "output_type": "stream"
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_huggingface import HuggingFacePipeline\n",
        "from transformers import AutoModelForCausalLM, AutoTokenizer, pipeline"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-07-18T13:01:12.639434Z",
          "iopub.execute_input": "2025-07-18T13:01:12.639667Z",
          "iopub.status.idle": "2025-07-18T13:01:55.277906Z",
          "shell.execute_reply.started": "2025-07-18T13:01:12.639649Z",
          "shell.execute_reply": "2025-07-18T13:01:55.277373Z"
        },
        "id": "mn_zLsI43nAM",
        "outputId": "d5b7450a-8c5f-4331-f069-0d18b66add5d"
      },
      "outputs": [
        {
          "name": "stderr",
          "text": "2025-07-18 13:01:35.704508: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\nWARNING: All log messages before absl::InitializeLog() is called are written to STDERR\nE0000 00:00:1752843696.074868      36 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\nE0000 00:00:1752843696.181429      36 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
          "output_type": "stream"
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "model_id=\"gpt2\"\n",
        "model=AutoModelForCausalLM.from_pretrained(model_id)\n",
        "tokenizer=AutoTokenizer.from_pretrained(model_id)"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-07-18T13:01:55.278648Z",
          "iopub.execute_input": "2025-07-18T13:01:55.279189Z",
          "iopub.status.idle": "2025-07-18T13:02:00.334242Z",
          "shell.execute_reply.started": "2025-07-18T13:01:55.279161Z",
          "shell.execute_reply": "2025-07-18T13:02:00.333098Z"
        },
        "id": "IlIwBSlV3nAM",
        "outputId": "4155d713-629c-4b0f-924b-1d1da3e8f072",
        "colab": {
          "referenced_widgets": [
            "788154c39a8c42208158cf3e58ba3f14",
            "28cf2e7513534900af61a0eab2d8468a",
            "988202ea34804f9e98d79f798f56ba82",
            "c35ca05c0da34e348966a40439eff65f",
            "e5551f6b8a18473f96c54656ea17b895",
            "d2dab81ffc8c43a0bc579670caaea7f5",
            "3bc090a8711a4760a6c3b90ff2d0b9e0"
          ]
        }
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "config.json:   0%|          | 0.00/665 [00:00<?, ?B/s]",
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "788154c39a8c42208158cf3e58ba3f14"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "model.safetensors:   0%|          | 0.00/548M [00:00<?, ?B/s]",
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "28cf2e7513534900af61a0eab2d8468a"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "generation_config.json:   0%|          | 0.00/124 [00:00<?, ?B/s]",
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "988202ea34804f9e98d79f798f56ba82"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "tokenizer_config.json:   0%|          | 0.00/26.0 [00:00<?, ?B/s]",
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "c35ca05c0da34e348966a40439eff65f"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "vocab.json:   0%|          | 0.00/1.04M [00:00<?, ?B/s]",
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "e5551f6b8a18473f96c54656ea17b895"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "merges.txt:   0%|          | 0.00/456k [00:00<?, ?B/s]",
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "d2dab81ffc8c43a0bc579670caaea7f5"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "tokenizer.json:   0%|          | 0.00/1.36M [00:00<?, ?B/s]",
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "3bc090a8711a4760a6c3b90ff2d0b9e0"
            }
          },
          "metadata": {}
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "pipe=pipeline(\"text-generation\",model=model,tokenizer=tokenizer,max_new_tokens=100)\n",
        "hf=HuggingFacePipeline(pipeline=pipe)"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-07-18T13:02:00.336823Z",
          "iopub.execute_input": "2025-07-18T13:02:00.337352Z",
          "iopub.status.idle": "2025-07-18T13:02:00.725759Z",
          "shell.execute_reply.started": "2025-07-18T13:02:00.337319Z",
          "shell.execute_reply": "2025-07-18T13:02:00.725166Z"
        },
        "id": "bmp-cSHu3nAM",
        "outputId": "e994b1d7-101c-4e28-a0c4-1f4cc020d4a6"
      },
      "outputs": [
        {
          "name": "stderr",
          "text": "Device set to use cuda:0\n",
          "output_type": "stream"
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "hf"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-07-18T13:02:00.726576Z",
          "iopub.execute_input": "2025-07-18T13:02:00.726856Z",
          "iopub.status.idle": "2025-07-18T13:02:00.732064Z",
          "shell.execute_reply.started": "2025-07-18T13:02:00.726832Z",
          "shell.execute_reply": "2025-07-18T13:02:00.731499Z"
        },
        "id": "rlMt1naw3nAN",
        "outputId": "a7696e5f-8136-44cb-e58c-22b2e6e94778"
      },
      "outputs": [
        {
          "execution_count": 18,
          "output_type": "execute_result",
          "data": {
            "text/plain": "HuggingFacePipeline(pipeline=<transformers.pipelines.text_generation.TextGenerationPipeline object at 0x798f85c55550>, model_id='gpt2')"
          },
          "metadata": {}
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "hf.invoke(\"What is machine learning\")"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-07-18T13:02:00.732743Z",
          "iopub.execute_input": "2025-07-18T13:02:00.732941Z",
          "iopub.status.idle": "2025-07-18T13:02:02.801649Z",
          "shell.execute_reply.started": "2025-07-18T13:02:00.732926Z",
          "shell.execute_reply": "2025-07-18T13:02:02.800733Z"
        },
        "id": "fD8BvTsn3nAN",
        "outputId": "6f934ce2-92a4-4e70-b29c-82b6a3483bb5"
      },
      "outputs": [
        {
          "name": "stderr",
          "text": "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
          "output_type": "stream"
        },
        {
          "execution_count": 19,
          "output_type": "execute_result",
          "data": {
            "text/plain": "'What is machine learning?\\n\\nMachine learning is a new field where machine learning is really coming to the forefront. Machine learning is more complicated than you might think. The problem is that, in a lot of fields, there is still a lot of information that is still not fully understood. This is why machine learning is so important.\\n\\nMachine learning is based on a set of algorithms that have been assembled from the data that are used in a given field to perform certain tasks. In machine learning, these algorithms are'"
          },
          "metadata": {}
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "gpu_llm = HuggingFacePipeline.from_model_id(\n",
        "    model_id=\"gpt2\",\n",
        "    task=\"text-generation\",\n",
        "    device_map=\"auto\",  # automatically chooses GPU if available\n",
        "    pipeline_kwargs={\"max_new_tokens\": 100},\n",
        ")\n"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-07-18T13:02:02.802481Z",
          "iopub.execute_input": "2025-07-18T13:02:02.802747Z",
          "iopub.status.idle": "2025-07-18T13:02:03.873545Z",
          "shell.execute_reply.started": "2025-07-18T13:02:02.802723Z",
          "shell.execute_reply": "2025-07-18T13:02:03.872863Z"
        },
        "id": "NcI8Kwd03nAN",
        "outputId": "b3195692-3d7b-4864-cbe3-106327d3e7c4"
      },
      "outputs": [
        {
          "name": "stderr",
          "text": "Device set to use cuda:0\n",
          "output_type": "stream"
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_core.prompts import PromptTemplate\n",
        "\n",
        "template = \"\"\"Question: {question}\n",
        "\n",
        "Answer: Let's think step by step.\"\"\"\n",
        "prompt = PromptTemplate.from_template(template)"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-07-18T13:02:03.874332Z",
          "iopub.execute_input": "2025-07-18T13:02:03.874926Z",
          "iopub.status.idle": "2025-07-18T13:02:03.878579Z",
          "shell.execute_reply.started": "2025-07-18T13:02:03.874899Z",
          "shell.execute_reply": "2025-07-18T13:02:03.877857Z"
        },
        "id": "Sq0WglFS3nAN"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "chain=prompt|gpu_llm"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-07-18T13:02:03.879299Z",
          "iopub.execute_input": "2025-07-18T13:02:03.87954Z",
          "iopub.status.idle": "2025-07-18T13:02:03.896581Z",
          "shell.execute_reply.started": "2025-07-18T13:02:03.879517Z",
          "shell.execute_reply": "2025-07-18T13:02:03.895911Z"
        },
        "id": "mevHQXXS3nAN"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "question=\"What is artificial intelligence?\"\n",
        "chain.invoke({\"question\":question})"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-07-18T13:02:03.897196Z",
          "iopub.execute_input": "2025-07-18T13:02:03.89744Z",
          "iopub.status.idle": "2025-07-18T13:02:05.245313Z",
          "shell.execute_reply.started": "2025-07-18T13:02:03.897425Z",
          "shell.execute_reply": "2025-07-18T13:02:05.244484Z"
        },
        "id": "-EIHMfU43nAN",
        "outputId": "3ead120e-e02f-44c9-95fd-afe258e138a2"
      },
      "outputs": [
        {
          "execution_count": 23,
          "output_type": "execute_result",
          "data": {
            "text/plain": "\"Question: What is artificial intelligence?\\n\\nAnswer: Let's think step by step.\\n\\nLet's start by looking at the real world. Many people are saying the same thing about computer programs and I have the same feeling.\\n\\nBut what is this artificial intelligence?\\n\\nThis is a human-like process that can do something without thinking about it.\\n\\nWe should not worry about it.\\n\\nWe don't need it.\\n\\nTo be perfectly honest, I think we do need it.\\n\\nI am absolutely convinced that it is the most important thing\""
          },
          "metadata": {}
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "trusted": true,
        "id": "3sCbgr0j3nAN"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "trusted": true,
        "id": "UvF9B-H43nAN"
      },
      "outputs": [],
      "execution_count": null
    }
  ]
}